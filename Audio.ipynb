{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Design ex2 - CoE: textual and audio features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(trainpath = \"./data/CoE_dataset_icpr/Dev_Set/audio_descriptors/*\",\n",
    "               testpath = \"./data/CoE_dataset_icpr/Test_Set/audio_descriptors/*\",\n",
    "              trainrefpath = \"./data/CoE_dataset_icpr/Dev_Set/CoeDevelopmentTrainingdata.csv\",\n",
    "              testrefpath = \"./data/CoE_dataset_icpr/Dev_Set/CoeDevelopmentTestdata.csv\"):\n",
    "    \"\"\" loads all audio data and includes the target variable\n",
    "    kwargs:\n",
    "        trainpath: path to the folder containing all audio descriptor csv files of the train set\n",
    "        testpath: path to the folder containing all audio descriptor csv files of the test set\n",
    "        trainrefpath: path to the csv containing filename, movie name and the target variable for the train set\n",
    "        testrefpath: path to the csv containing filename, movie name and the target variable for the test set\n",
    "    \"\"\"\n",
    "    train = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "    trainfiles = []\n",
    "    testfiles = []\n",
    "\n",
    "    # load training data\n",
    "    for csvpath in tqdm(glob.glob(trainpath), desc='Loading audio train data'):\n",
    "        trainfiles.append(csvpath.split('/')[-1].split('.csv')[0])\n",
    "        tmp = pd.DataFrame(pd.read_csv(csvpath, header=None)).mean(axis=1)\n",
    "        train = train.append(pd.DataFrame(tmp.values.flatten()).transpose())\n",
    "\n",
    "    # load test data\n",
    "    for csvpath in tqdm(glob.glob(testpath), desc='Loading audio test data'):\n",
    "        testfiles.append(csvpath.split('/')[-1].split('.csv')[0])\n",
    "        tmp = pd.DataFrame(pd.read_csv(csvpath, header=None)).mean(axis=1)\n",
    "        test = test.append(pd.DataFrame(tmp.values.flatten()).transpose())\n",
    "\n",
    "    # add filename and target variable\n",
    "    train['fname'] = trainfiles\n",
    "    test['fname'] = testfiles\n",
    "    train = train.merge(pd.read_csv(trainrefpath)[['file_name', 'goodforairplanes']], left_on='fname', right_on='file_name').drop(columns=['file_name'])\n",
    "    test = test.merge(pd.read_csv(testrefpath)[['file_name', 'goodforairplanes']], left_on='fname', right_on='file_name').drop(columns=['file_name'])\n",
    "    \n",
    "    # set file name as index\n",
    "    train.set_index(['fname'], inplace=True)\n",
    "    test.set_index(['fname'], inplace=True)\n",
    "    \n",
    "    # replace NAs in audio\n",
    "    train = train.fillna(0)\n",
    "    test = test.fillna(0)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text():\n",
    "    train = pd.read_csv(\"./data/CoE_dataset_icpr/Dev_Set/text_descriptors/tdf_idf_dev.csv\")\n",
    "    test = pd.read_csv(\"./data/CoE_dataset_icpr/Test_Set/text_descriptors/tdf_idf_test.csv\")\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading audio train data: 100%|██████████| 95/95 [00:50<00:00,  1.87it/s]\n",
      "Loading audio test data: 100%|██████████| 223/223 [01:56<00:00,  1.92it/s]\n"
     ]
    }
   ],
   "source": [
    "audio_train, audio_test = load_audio()\n",
    "text_train, text_test = load_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Las Vegas Wrapper for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LVW(classifier_function, tX, ty, vX, vy, K, original_features):\n",
    "    \n",
    "    acc = 0\n",
    "    k = 0\n",
    "    C = len(original_features)\n",
    "    \n",
    "    while k < K:\n",
    "        #print('k: ', k)\n",
    "        ran_choice = range(1,len(original_features)-1)\n",
    "        S1 = random.sample(original_features, random.choice(ran_choice))\n",
    "        C1 = len(S1)\n",
    "        \n",
    "        x_train = tX[tX.columns.intersection(S1)]\n",
    "        x_test = vX[vX.columns.intersection(S1)]\n",
    "        \n",
    "        acc1 = classifier_function(tX, ty, vX, vy, acc = True)\n",
    "        \n",
    "        if (acc1 > acc) or (acc1 == acc and C1 < C):\n",
    "            k = 0\n",
    "            acc = acc1\n",
    "            C = C1\n",
    "            S = S1\n",
    "        \n",
    "        else:\n",
    "            k += 1\n",
    "            \n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_tvar(train, test, target_var):\n",
    "    \"\"\" seperate training/test set and the target variable\n",
    "    kwargs:\n",
    "        train: dataframe containing dependent and independent variables\n",
    "        test: dataframe containing dependent and independent variables\n",
    "        target_var: column name of the target variable as a string\n",
    "    \"\"\"\n",
    "    if target_var in train.columns:\n",
    "        train_y = train[target_var]\n",
    "        train_x = train.drop(columns=target_var)\n",
    "    if target_var in test.columns:\n",
    "        test_y = test[target_var]\n",
    "        test_x = test.drop(columns=target_var)\n",
    "    \n",
    "    return train_y, train_x, test_y, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seb/.anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/seb/.anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-score</th>\n",
       "      <th>Training time (s)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[0.29411764705882354, 0.3870967741935484]</td>\n",
       "      <td>[0.20833333333333334, 0.5]</td>\n",
       "      <td>[0.24390243902439027, 0.43636363636363634]</td>\n",
       "      <td>0.002007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gradient Boosting Tree</td>\n",
       "      <td>[0.4, 0.391304347826087]</td>\n",
       "      <td>[0.4166666666666667, 0.375]</td>\n",
       "      <td>[0.4081632653061225, 0.3829787234042554]</td>\n",
       "      <td>0.040689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KNN</td>\n",
       "      <td>[0.6086956521739131, 0.6]</td>\n",
       "      <td>[0.5833333333333334, 0.625]</td>\n",
       "      <td>[0.5957446808510638, 0.6122448979591836]</td>\n",
       "      <td>0.000675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SVM</td>\n",
       "      <td>[0.55, 0.5357142857142857]</td>\n",
       "      <td>[0.4583333333333333, 0.625]</td>\n",
       "      <td>[0.5, 0.576923076923077]</td>\n",
       "      <td>0.001297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Naive bayes</td>\n",
       "      <td>[0.5161290322580645, 0.5294117647058824]</td>\n",
       "      <td>[0.6666666666666666, 0.375]</td>\n",
       "      <td>[0.5818181818181819, 0.4390243902439025]</td>\n",
       "      <td>0.000799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Precision  \\\n",
       "Algorithm                                                           \n",
       "Logistic Regression     [0.29411764705882354, 0.3870967741935484]   \n",
       "Gradient Boosting Tree                   [0.4, 0.391304347826087]   \n",
       "KNN                                     [0.6086956521739131, 0.6]   \n",
       "SVM                                    [0.55, 0.5357142857142857]   \n",
       "Naive bayes              [0.5161290322580645, 0.5294117647058824]   \n",
       "\n",
       "                                             Recall  \\\n",
       "Algorithm                                             \n",
       "Logistic Regression      [0.20833333333333334, 0.5]   \n",
       "Gradient Boosting Tree  [0.4166666666666667, 0.375]   \n",
       "KNN                     [0.5833333333333334, 0.625]   \n",
       "SVM                     [0.4583333333333333, 0.625]   \n",
       "Naive bayes             [0.6666666666666666, 0.375]   \n",
       "\n",
       "                                                           F-score  \\\n",
       "Algorithm                                                            \n",
       "Logistic Regression     [0.24390243902439027, 0.43636363636363634]   \n",
       "Gradient Boosting Tree    [0.4081632653061225, 0.3829787234042554]   \n",
       "KNN                       [0.5957446808510638, 0.6122448979591836]   \n",
       "SVM                                       [0.5, 0.576923076923077]   \n",
       "Naive bayes               [0.5818181818181819, 0.4390243902439025]   \n",
       "\n",
       "                        Training time (s)  \n",
       "Algorithm                                  \n",
       "Logistic Regression              0.002007  \n",
       "Gradient Boosting Tree           0.040689  \n",
       "KNN                              0.000675  \n",
       "SVM                              0.001297  \n",
       "Naive bayes                      0.000799  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict with classifier name: time spent for fitting and classifier obejcts\n",
    "classifier = {\"Logistic Regression\": LogisticRegression(),\n",
    "              \"Gradient Boosting Tree\": GradientBoostingClassifier(),\n",
    "              \"KNN\": KNeighborsClassifier(),\n",
    "              \"SVM\": SVC(),\n",
    "              \"Naive bayes\": GaussianNB()}\n",
    "\n",
    "res = pd.DataFrame(columns=['Algorithm', 'Precision', 'Recall', 'F-score', 'Training time (s)']).set_index(['Algorithm'])\n",
    "\n",
    "for c in classifier:\n",
    "    train_y, train_x, test_y, test_x = seperate_tvar(audio_train, audio_test, 'goodforairplanes')\n",
    "    \n",
    "    # apply LVW feature selection on train_x and test_x\n",
    "#     features = LVW(classifier[c], train_x, train_y, test_x, test_y, 500, range(0,train_x.shape[1]-1))\n",
    "#     train_x = train_x[train_x.columns.intersection(features)]\n",
    "#     test_x = test_x[test_x.columns.intersection(features)]\n",
    "    \n",
    "    \n",
    "    model = classifier[c]\n",
    "    start_time = time.time()\n",
    "    model.fit(train_x, train_y)\n",
    "    dur = time.time() - start_time\n",
    "    pred_y = model.predict(test_x)\n",
    "    prfs = precision_recall_fscore_support(test_y, pred_y)\n",
    "    res.loc[c] = [prfs[0], prfs[1], prfs[2], dur]\n",
    "\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
