KNN using LVW Feature Selection
---------------------------------------------------------------------------------------------------
KNN - Keep both rows
{'Precision': 0.6514285714285715, 'Recall': 0.6599999999999999, 'F1': 0.6443939393939394}
---------------------------------------------------------------------------------------------------
KNN - Keep only columnwise sum
{'Precision': 0.663809523809524, 'Recall': 0.74, 'F1': 0.6975757575757576}
---------------------------------------------------------------------------------------------------
KNN - Keep only columnwise mean
{'Precision': 0.650952380952381, 'Recall': 0.76, 'F1': 0.6889393939393939}
---------------------------------------------------------------------------------------------------
KNN - Keep only columnwise max
{'Precision': 0.663809523809524, 'Recall': 0.7, 'F1': 0.6638095238095238}
---------------------------------------------------------------------------------------------------
KNN - Keep only columnwise min
{'Precision': 0.6007936507936508, 'Recall': 0.72, 'F1': 0.6441558441558441}
---------------------------------------------------------------------------------------------------
KNN - Keep only the first row
{'Precision': 0.6219047619047618, 'Recall': 0.6599999999999999, 'F1': 0.6156138306138306}
---------------------------------------------------------------------------------------------------
KNN - Keep only the last row
{'Precision': 0.6948412698412698, 'Recall': 0.72, 'F1': 0.6936507936507936}
---------------------------------------------------------------------------------------------------

Decision Tree using LVW Feature Selection
---------------------------------------------------------------------------------------------------
Decision Tree - Keep both rows
{'Precision': 0.6122222222222222, 'Recall': 0.6599999999999999, 'F1': 0.5833333333333333}
---------------------------------------------------------------------------------------------------
Decision Tree - Keep only columnwise sum
{'Precision': 0.6053968253968254, 'Recall': 0.6399999999999999, 'F1': 0.6269153069153071}
---------------------------------------------------------------------------------------------------
Decision Tree - Keep only columnwise mean
{'Precision': 0.6519047619047618, 'Recall': 0.76, 'F1': 0.6662404262404262}
---------------------------------------------------------------------------------------------------
Decision Tree - Keep only columnwise max
{'Precision': 0.5936904761904762, 'Recall': 0.6, 'F1': 0.5670940170940172}
---------------------------------------------------------------------------------------------------
Decision Tree - Keep only columnwise min
{'Precision': 0.5334920634920635, 'Recall': 0.6200000000000001, 'F1': 0.5475019425019425}
---------------------------------------------------------------------------------------------------
Decision Tree - Keep only the first row
{'Precision': 0.6512301587301588, 'Recall': 0.76, 'F1': 0.6782933732933734}
---------------------------------------------------------------------------------------------------
Decision Tree - Keep only the last row
{'Precision': 0.5971428571428571, 'Recall': 0.6599999999999999, 'F1': 0.5914085914085914}
---------------------------------------------------------------------------------------------------

Logistic Regression using LVW Feature Selection
---------------------------------------------------------------------------------------------------
Logistic Regression - Keep both rows
{'Precision': 0.6430952380952382, 'Recall': 0.6799999999999999, 'F1': 0.6527272727272728}
---------------------------------------------------------------------------------------------------
Logistic Regression - Keep only columnwise sum
{'Precision': 0.6, 'Recall': 0.78, 'F1': 0.6695027195027196}
---------------------------------------------------------------------------------------------------
Logistic Regression - Keep only columnwise mean
{'Precision': 0.5953174603174604, 'Recall': 0.8400000000000001, 'F1': 0.6922677322677323}
---------------------------------------------------------------------------------------------------
Logistic Regression - Keep only columnwise max
{'Precision': 0.6431746031746032, 'Recall': 0.76, 'F1': 0.685088245088245}
---------------------------------------------------------------------------------------------------
Logistic Regression - Keep only columnwise min
{'Precision': 0.5865476190476191, 'Recall': 0.8, 'F1': 0.672890442890443}
---------------------------------------------------------------------------------------------------
Logistic Regression - Keep only the first row
{'Precision': 0.5732539682539682, 'Recall': 0.8000000000000002, 'F1': 0.66003663003663}
---------------------------------------------------------------------------------------------------
Logistic Regression - Keep only the last row
{'Precision': 0.6083333333333334, 'Recall': 0.74, 'F1': 0.650949050949051}
---------------------------------------------------------------------------------------------------

SVM using LVW Feature Selection
---------------------------------------------------------------------------------------------------
SVM - Keep both rows
{'Precision': 0.47055555555555556, 'Recall': 0.7, 'F1': 0.5570940170940172}
---------------------------------------------------------------------------------------------------
SVM - Keep only columnwise sum
{'Precision': 0.5433333333333332, 'Recall': 0.96, 'F1': 0.6885714285714285}
---------------------------------------------------------------------------------------------------
SVM - Keep only columnwise mean
{'Precision': 0.4666666666666666, 'Recall': 0.56, 'F1': 0.43809523809523804}
---------------------------------------------------------------------------------------------------
SVM - Keep only columnwise max
{'Precision': 0.4666666666666666, 'Recall': 0.64, 'F1': 0.47619047619047616}
---------------------------------------------------------------------------------------------------
SVM - Keep only columnwise min
{'Precision': 0.5638095238095239, 'Recall': 0.8, 'F1': 0.6582983682983683}
---------------------------------------------------------------------------------------------------
SVM - Keep only the first row
{'Precision': 0.5388888888888889, 'Recall': 1.0, 'F1': 0.7}
---------------------------------------------------------------------------------------------------
SVM - Keep only the last row
{'Precision': 0.4666666666666666, 'Recall': 0.56, 'F1': 0.43809523809523804}
---------------------------------------------------------------------------------------------------

Random Forest using all features
---------------------------------------------------------------------------------------------------
Random Forest - Keep both rows
{'Precision': 0.6461904761904762, 'Recall': 0.5399999999999999, 'F1': 0.6161871461871462}
---------------------------------------------------------------------------------------------------
Random Forest - Keep only columnwise sum
{'Precision': 0.5938095238095238, 'Recall': 0.54, 'F1': 0.5831546231546231}
---------------------------------------------------------------------------------------------------
Random Forest - Keep only columnwise mean
{'Precision': 0.5850000000000001, 'Recall': 0.5, 'F1': 0.5614485514485514}
---------------------------------------------------------------------------------------------------
Random Forest - Keep only columnwise max
{'Precision': 0.5411904761904762, 'Recall': 0.6599999999999999, 'F1': 0.522041847041847}
---------------------------------------------------------------------------------------------------
Random Forest - Keep only columnwise min
{'Precision': 0.5970634920634921, 'Recall': 0.52, 'F1': 0.5145543345543345}
---------------------------------------------------------------------------------------------------
Random Forest - Keep only the first row
{'Precision': 0.6388095238095237, 'Recall': 0.56, 'F1': 0.6098445998445998}
---------------------------------------------------------------------------------------------------
Random Forest - Keep only the last row
{'Precision': 0.5952380952380952, 'Recall': 0.5799999999999998, 'F1': 0.416060606060606}
---------------------------------------------------------------------------------------------------

AdaBoost using LVW Feature Selection
---------------------------------------------------------------------------------------------------
AdaBoost - Keep both rows
{'Precision': 0.5820238095238095, 'Recall': 0.6799999999999999, 'F1': 0.6152447552447552}
---------------------------------------------------------------------------------------------------
AdaBoost - Keep only columnwise sum
{'Precision': 0.6983730158730158, 'Recall': 0.74, 'F1': 0.6957686757686757}
---------------------------------------------------------------------------------------------------
AdaBoost - Keep only columnwise mean
{'Precision': 0.5865476190476191, 'Recall': 0.7, 'F1': 0.6301554001554002}
---------------------------------------------------------------------------------------------------
AdaBoost - Keep only columnwise max
{'Precision': 0.6842857142857144, 'Recall': 0.6599999999999999, 'F1': 0.6381818181818182}
---------------------------------------------------------------------------------------------------
AdaBoost - Keep only columnwise min
{'Precision': 0.5808333333333333, 'Recall': 0.6799999999999999, 'F1': 0.6408391608391609}
---------------------------------------------------------------------------------------------------
AdaBoost - Keep only the first row
{'Precision': 0.5444444444444445, 'Recall': 1.0, 'F1': 0.7047619047619047}
---------------------------------------------------------------------------------------------------
AdaBoost - Keep only the last row
{'Precision': 0.6373809523809524, 'Recall': 0.64, 'F1': 0.6275990675990677}
---------------------------------------------------------------------------------------------------

Gradient Boosting Tree using LVW Feature Selection
---------------------------------------------------------------------------------------------------
Gradient Boosting Tree - Keep both rows
{'Precision': 0.5555952380952381, 'Recall': 0.6799999999999999, 'F1': 0.616037296037296}
---------------------------------------------------------------------------------------------------
Gradient Boosting Tree - Keep only columnwise sum
{'Precision': 0.5868253968253968, 'Recall': 0.7, 'F1': 0.6143667443667444}
---------------------------------------------------------------------------------------------------
Gradient Boosting Tree - Keep only columnwise mean
{'Precision': 0.5724206349206349, 'Recall': 0.72, 'F1': 0.6098235098235099}
---------------------------------------------------------------------------------------------------
Gradient Boosting Tree - Keep only columnwise max
{'Precision': 0.5803174603174603, 'Recall': 0.7, 'F1': 0.6229204129204129}
---------------------------------------------------------------------------------------------------
Gradient Boosting Tree - Keep only columnwise min
{'Precision': 0.5744444444444444, 'Recall': 0.6799999999999999, 'F1': 0.6077056277056276}
---------------------------------------------------------------------------------------------------
Gradient Boosting Tree - Keep only the first row
{'Precision': 0.6415079365079365, 'Recall': 0.74, 'F1': 0.6776134976134978}
---------------------------------------------------------------------------------------------------
Gradient Boosting Tree - Keep only the last row
{'Precision': 0.5635714285714285, 'Recall': 0.58, 'F1': 0.6167171717171718}
---------------------------------------------------------------------------------------------------