{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 250\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import random\n",
    "import ntpath\n",
    "import os\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision_tree</th>\n",
       "      <th>knn</th>\n",
       "      <th>nearest_mean</th>\n",
       "      <th>logistic_regression</th>\n",
       "      <th>svm</th>\n",
       "      <th>bagging</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>adaboost</th>\n",
       "      <th>gradient_boost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Gradient Boosting Tree</th>\n",
       "      <th>goodforairplanes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Seventh Son</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welcome to Me</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Judge</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transformers  Age of Extinction</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Normal Heart</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 decision_tree  knn  nearest_mean  \\\n",
       "movie                                                               \n",
       "Seventh Son                                  0    1             0   \n",
       "Welcome to Me                                1    0             1   \n",
       "The Judge                                    1    1             0   \n",
       "Transformers  Age of Extinction              0    0             0   \n",
       "The Normal Heart                             1    1             1   \n",
       "\n",
       "                                 logistic_regression  svm  bagging  \\\n",
       "movie                                                                \n",
       "Seventh Son                                        0    1        0   \n",
       "Welcome to Me                                      1    1        1   \n",
       "The Judge                                          1    1        1   \n",
       "Transformers  Age of Extinction                    0    1        1   \n",
       "The Normal Heart                                   1    1        1   \n",
       "\n",
       "                                 random_forest  adaboost  gradient_boost  KNN  \\\n",
       "movie                                                                           \n",
       "Seventh Son                                  0         0               0    0   \n",
       "Welcome to Me                                1         1               1    0   \n",
       "The Judge                                    1         1               1    1   \n",
       "Transformers  Age of Extinction              1         0               0    0   \n",
       "The Normal Heart                             1         1               1    0   \n",
       "\n",
       "                                 Decision Tree  Logistic Regression  SVM  \\\n",
       "movie                                                                      \n",
       "Seventh Son                                  0                    1    1   \n",
       "Welcome to Me                                1                    0    1   \n",
       "The Judge                                    1                    1    1   \n",
       "Transformers  Age of Extinction              0                    0    1   \n",
       "The Normal Heart                             0                    1    1   \n",
       "\n",
       "                                 Random Forest  AdaBoost  \\\n",
       "movie                                                      \n",
       "Seventh Son                                  1         1   \n",
       "Welcome to Me                                1         1   \n",
       "The Judge                                    1         1   \n",
       "Transformers  Age of Extinction              0         0   \n",
       "The Normal Heart                             1         1   \n",
       "\n",
       "                                 Gradient Boosting Tree  goodforairplanes  \n",
       "movie                                                                      \n",
       "Seventh Son                                           1                 1  \n",
       "Welcome to Me                                         1                 0  \n",
       "The Judge                                             1                 0  \n",
       "Transformers  Age of Extinction                       0                 0  \n",
       "The Normal Heart                                      0                 1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load stacking files\n",
    "metadata_train = pd.read_csv(r'out/predictions_metadata_dev.csv', index_col = 0, header = 0)\n",
    "\n",
    "textual_train = pd.read_csv(r'out/text_yhat_train.csv', index_col = 10, header = 0)\n",
    "textual_train.index.names = ['movie']\n",
    "textual_train = textual_train.drop('goodforairplanes', axis='columns')\n",
    "\n",
    "visual_train = pd.read_csv(r'out/visual_predictions_train.csv', index_col = 0, header = 0)\n",
    "#visual_train = visual_train.drop('goodforairplanes', axis='columns')\n",
    "\n",
    "audio_train = pd.read_csv(r'out/audio_yhat_train.csv', index_col = 10, header = 0)\n",
    "audio_train.index.names = ['movie']\n",
    "\n",
    "# merge dataframes\n",
    "#dfs = [metadata_train, textual_train, visual_train, audio_train]\n",
    "dfs = [metadata_train, visual_train]\n",
    "majority_train = reduce(lambda left, right: pd.merge(left, right, on = 'movie'), dfs)\n",
    "\n",
    "# rearrange columns\n",
    "majority_train = majority_train[[c for c in majority_train if c not in ['goodforairplanes']] + ['goodforairplanes']]\n",
    "majority_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision_tree</th>\n",
       "      <th>knn</th>\n",
       "      <th>nearest_mean</th>\n",
       "      <th>logistic_regression</th>\n",
       "      <th>svm</th>\n",
       "      <th>bagging</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>adaboost</th>\n",
       "      <th>gradient_boost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Gradient Boosting Tree</th>\n",
       "      <th>goodforairplanes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10.000 Km</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12 Years a Slave</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21 Jump Street</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 States</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aanmodderfakker</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  decision_tree  knn  nearest_mean  logistic_regression  svm  \\\n",
       "movie                                                                          \n",
       "10.000 Km                     1    0             1                    1    1   \n",
       "12 Years a Slave              0    1             0                    0    1   \n",
       "21 Jump Street                0    1             1                    1    1   \n",
       "2 States                      1    0             0                    1    1   \n",
       "Aanmodderfakker               1    0             1                    1    1   \n",
       "\n",
       "                  bagging  random_forest  adaboost  gradient_boost  KNN  \\\n",
       "movie                                                                     \n",
       "10.000 Km               1              1         1               1    1   \n",
       "12 Years a Slave        1              0         0               0    0   \n",
       "21 Jump Street          0              0         0               0    0   \n",
       "2 States                1              1         1               1    0   \n",
       "Aanmodderfakker         1              1         1               1    1   \n",
       "\n",
       "                  Decision Tree  Logistic Regression  SVM  Random Forest  \\\n",
       "movie                                                                      \n",
       "10.000 Km                     1                    1    1              1   \n",
       "12 Years a Slave              0                    1    1              0   \n",
       "21 Jump Street                0                    1    1              0   \n",
       "2 States                      1                    0    1              1   \n",
       "Aanmodderfakker               0                    0    1              1   \n",
       "\n",
       "                  AdaBoost  Gradient Boosting Tree  goodforairplanes  \n",
       "movie                                                                 \n",
       "10.000 Km                1                       1                 1  \n",
       "12 Years a Slave         0                       0                 1  \n",
       "21 Jump Street           0                       0                 1  \n",
       "2 States                 1                       0                 1  \n",
       "Aanmodderfakker          0                       0                 1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load stacking files\n",
    "metadata_test = pd.read_csv(r'out/predictions_metadata_test.csv', index_col = 0, header = 0)\n",
    "metadata_test.index.names = ['movie']\n",
    "\n",
    "textual_test = pd.read_csv(r'out/text_yhat_test.csv', index_col = 10, header = 0)\n",
    "textual_test.index.names = ['movie']\n",
    "textual_test = textual_test.drop('goodforairplanes', axis='columns')\n",
    "\n",
    "visual_test = pd.read_csv(r'out/visual_predictions_test.csv', index_col = 0, header = 0)\n",
    "#visual_test = visual_test.drop('goodforairplanes', axis='columns')\n",
    "\n",
    "audio_test = pd.read_csv(r'out/audio_yhat_test.csv', index_col = 10, header = 0)\n",
    "audio_test.index.names = ['movie']\n",
    "\n",
    "# merge dataframes\n",
    "#dfs = [metadata_test, textual_test, visual_test, audio_test]\n",
    "dfs = [metadata_test, visual_test]\n",
    "majority_test = reduce(lambda left, right: pd.merge(left, right, on = 'movie'), dfs)\n",
    "\n",
    "# rearrange columns\n",
    "majority_test = majority_test[[c for c in majority_test if c not in ['goodforairplanes']] + ['goodforairplanes']]\n",
    "majority_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_majority(li):\n",
    "    \n",
    "    myMap = {}\n",
    "    maximum = ( '', 0 ) # (occurring element, occurrences)\n",
    "    \n",
    "    for element in li:\n",
    "        \n",
    "        if element in myMap: \n",
    "            myMap[element] += 1\n",
    "            \n",
    "        else: \n",
    "            myMap[element] = 1\n",
    "\n",
    "        # Keep track of maximum on the go\n",
    "        if myMap[element] > maximum[1]: maximum = (element, myMap[element])\n",
    "\n",
    "    return maximum[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting(predictions_df):\n",
    "    \n",
    "    X = predictions_df.iloc[:, :-1]\n",
    "    y = predictions_df.iloc[:,-1]\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(0,len(X.index)):\n",
    "\n",
    "        li = X.iloc[i].tolist()\n",
    "        predictions.append(find_majority(li))\n",
    "\n",
    "    precision = precision_score(y, predictions)\n",
    "    recall = recall_score(y, predictions)\n",
    "    f1 = f1_score(y, predictions)\n",
    "\n",
    "    scores = {\"Precision\": precision, \"Recall\": recall, \"F1\": f1}\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Voting on the Train Set\n",
    "We apply Majority Voting on the training set without using cross-validation because cv would not make much sense here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision': 0.5882352941176471,\n",
       " 'Recall': 0.8163265306122449,\n",
       " 'F1': 0.6837606837606838}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority_scores_train = majority_voting(majority_train)\n",
    "majority_scores_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Voting on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision': 0.580952380952381,\n",
       " 'Recall': 0.7176470588235294,\n",
       " 'F1': 0.6421052631578948}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority_scores_test = majority_voting(majority_test)\n",
    "majority_scores_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Stacking\n",
    "We can reuse the train and test data from Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_stacking(df_train, df_test = None, CV = True):\n",
    "\n",
    "    log_reg = LogisticRegression(solver='lbfgs')  # solver='lbfgs' -> for not getting warnings\n",
    "\n",
    "    if CV:\n",
    "        X, y = df_train.iloc[:, :-1], df_train.iloc[:,-1]\n",
    "\n",
    "        cv_scores = cross_validate(log_reg, X, y, cv=10, scoring=['precision', 'recall', 'f1'])\n",
    "\n",
    "        precision = np.mean(cv_scores['test_precision'])\n",
    "        recall = np.mean(cv_scores['test_recall'])\n",
    "        f1 = np.mean(cv_scores['test_f1'])\n",
    "        \n",
    "    else:\n",
    "        X_train, y_train = df_train.iloc[:, :-1], df_train.iloc[:,-1]\n",
    "        X_test, y_test = df_test.iloc[:, :-1], df_test.iloc[:,-1]\n",
    "\n",
    "        log_reg.fit(X_train, y_train)\n",
    "        predictions = log_reg.predict(X_test)\n",
    "\n",
    "        precision = precision_score(y_test, predictions)\n",
    "        recall = recall_score(y_test, predictions)\n",
    "        f1 = f1_score(y_test, predictions)\n",
    "\n",
    "    scores = {\"Precision\": precision, \"Recall\": recall, \"F1\": f1}\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lable Stacking on the Train Set with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision': 0.6422619047619047, 'Recall': 0.67, 'F1': 0.638028638028638}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "label_stacking_scores_train = label_stacking(majority_train)\n",
    "label_stacking_scores_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Stacking on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision': 0.5344827586206896,\n",
       " 'Recall': 0.36470588235294116,\n",
       " 'F1': 0.4335664335664336}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "label_stacking_scores_test = label_stacking(majority_train, majority_test, CV = False)\n",
    "label_stacking_scores_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label-Feature Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Features Data and Merge with Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision_tree</th>\n",
       "      <th>knn</th>\n",
       "      <th>nearest_mean</th>\n",
       "      <th>logistic_regression</th>\n",
       "      <th>svm</th>\n",
       "      <th>bagging</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>adaboost</th>\n",
       "      <th>gradient_boost</th>\n",
       "      <th>country_Australia</th>\n",
       "      <th>...</th>\n",
       "      <th>824</th>\n",
       "      <th>825</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Gradient Boosting Tree</th>\n",
       "      <th>goodforairplanes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Seventh Son</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26201.0</td>\n",
       "      <td>14542.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welcome to Me</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32531.0</td>\n",
       "      <td>13753.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Judge</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>230400.0</td>\n",
       "      <td>119950.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Normal Heart</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>35320.0</td>\n",
       "      <td>20831.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Phantom Tollbooth</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73984.0</td>\n",
       "      <td>38355.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 942 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       decision_tree  knn  nearest_mean  logistic_regression  \\\n",
       "movie                                                                          \n",
       "Seventh Son                        0    1             0                    0   \n",
       "Welcome to Me                      1    0             1                    1   \n",
       "The Judge                          1    1             0                    1   \n",
       "The Normal Heart                   1    1             1                    1   \n",
       "The Phantom Tollbooth              0    1             1                    1   \n",
       "\n",
       "                       svm  bagging  random_forest  adaboost  gradient_boost  \\\n",
       "movie                                                                          \n",
       "Seventh Son              1        0              0         0               0   \n",
       "Welcome to Me            1        1              1         1               1   \n",
       "The Judge                1        1              1         1               1   \n",
       "The Normal Heart         1        1              1         1               1   \n",
       "The Phantom Tollbooth    1        1              1         1               1   \n",
       "\n",
       "                       country_Australia        ...              824  \\\n",
       "movie                                           ...                    \n",
       "Seventh Son                            0        ...          26201.0   \n",
       "Welcome to Me                          0        ...          32531.0   \n",
       "The Judge                              0        ...         230400.0   \n",
       "The Normal Heart                       0        ...          35320.0   \n",
       "The Phantom Tollbooth                  0        ...          73984.0   \n",
       "\n",
       "                            825  KNN  Decision Tree  Logistic Regression  SVM  \\\n",
       "movie                                                                           \n",
       "Seventh Son             14542.0    1              1                    1    1   \n",
       "Welcome to Me           13753.0    0              1                    0    1   \n",
       "The Judge              119950.0    1              1                    1    1   \n",
       "The Normal Heart        20831.0    0              1                    1    1   \n",
       "The Phantom Tollbooth   38355.0    0              1                    1    1   \n",
       "\n",
       "                       Random Forest  AdaBoost  Gradient Boosting Tree  \\\n",
       "movie                                                                    \n",
       "Seventh Son                        1         1                       1   \n",
       "Welcome to Me                      1         1                       0   \n",
       "The Judge                          1         1                       1   \n",
       "The Normal Heart                   1         0                       1   \n",
       "The Phantom Tollbooth              0         1                       1   \n",
       "\n",
       "                       goodforairplanes  \n",
       "movie                                    \n",
       "Seventh Son                           1  \n",
       "Welcome to Me                         0  \n",
       "The Judge                             0  \n",
       "The Normal Heart                      1  \n",
       "The Phantom Tollbooth                 1  \n",
       "\n",
       "[5 rows x 942 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load stacking files\n",
    "metadata_feature_train = pd.read_csv(r'out/meta_train.csv', index_col = 0, header = 0)\n",
    "\n",
    "textual_feature_train = pd.read_csv(r'out/text_yhat_train.csv', index_col = 10, header = 0)\n",
    "textual_feature_train.index.names = ['movie']\n",
    "textual_feature_train = textual_train.drop('goodforairplanes', axis='columns')\n",
    "\n",
    "visual_feature_train = pd.read_csv(r'out/visual_predictions_labels_train.csv', index_col = 0, header = 0)\n",
    "\n",
    "audio_feature_train = pd.read_csv(r'out/audio_yhat_train.csv', index_col = 10, header = 0)\n",
    "audio_feature_train.index.names = ['movie']\n",
    "\n",
    "# merge dataframes\n",
    "#dfs = [metadata_train, metadata_feature_train, textual_train, textual_feature_train, visual_feature_train, \n",
    "#       audio_train, audio_feature_train]\n",
    "dfs = [metadata_train, metadata_feature_train, visual_feature_train]\n",
    "features_train = reduce(lambda left, right: pd.merge(left, right, on = 'movie'), dfs)\n",
    "\n",
    "# rearrange columns\n",
    "features_train = features_train[[c for c in features_train if c not in ['goodforairplanes']] + ['goodforairplanes']]\n",
    "features_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Features Data and Merge with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision_tree</th>\n",
       "      <th>knn</th>\n",
       "      <th>nearest_mean</th>\n",
       "      <th>logistic_regression</th>\n",
       "      <th>svm</th>\n",
       "      <th>bagging</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>adaboost</th>\n",
       "      <th>gradient_boost</th>\n",
       "      <th>country_Australia</th>\n",
       "      <th>...</th>\n",
       "      <th>824</th>\n",
       "      <th>825</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Gradient Boosting Tree</th>\n",
       "      <th>goodforairplanes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10.000 Km</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>518400.0</td>\n",
       "      <td>269700.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12 Years a Slave</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30212.0</td>\n",
       "      <td>14583.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21 Jump Street</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>230400.0</td>\n",
       "      <td>119790.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 States</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>48676.0</td>\n",
       "      <td>34515.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aanmodderfakker</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2971.6</td>\n",
       "      <td>970.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 942 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  decision_tree  knn  nearest_mean  logistic_regression  svm  \\\n",
       "movie                                                                          \n",
       "10.000 Km                     1    0             1                    1    1   \n",
       "12 Years a Slave              0    1             0                    0    1   \n",
       "21 Jump Street                0    1             1                    1    1   \n",
       "2 States                      1    0             0                    1    1   \n",
       "Aanmodderfakker               1    0             1                    1    1   \n",
       "\n",
       "                  bagging  random_forest  adaboost  gradient_boost  \\\n",
       "movie                                                                \n",
       "10.000 Km               1              1         1               1   \n",
       "12 Years a Slave        1              0         0               0   \n",
       "21 Jump Street          0              0         0               0   \n",
       "2 States                1              1         1               1   \n",
       "Aanmodderfakker         1              1         1               1   \n",
       "\n",
       "                  country_Australia        ...              824        825  \\\n",
       "movie                                      ...                               \n",
       "10.000 Km                         0        ...         518400.0  269700.00   \n",
       "12 Years a Slave                  0        ...          30212.0   14583.00   \n",
       "21 Jump Street                    0        ...         230400.0  119790.00   \n",
       "2 States                          0        ...          48676.0   34515.00   \n",
       "Aanmodderfakker                   0        ...           2971.6     970.54   \n",
       "\n",
       "                  KNN  Decision Tree  Logistic Regression  SVM  Random Forest  \\\n",
       "movie                                                                           \n",
       "10.000 Km           1              1                    1    1              1   \n",
       "12 Years a Slave    0              0                    1    1              1   \n",
       "21 Jump Street      0              0                    1    1              0   \n",
       "2 States            0              1                    0    1              1   \n",
       "Aanmodderfakker     1              0                    0    1              1   \n",
       "\n",
       "                  AdaBoost  Gradient Boosting Tree  goodforairplanes  \n",
       "movie                                                                 \n",
       "10.000 Km                1                       1                 1  \n",
       "12 Years a Slave         0                       0                 1  \n",
       "21 Jump Street           0                       0                 1  \n",
       "2 States                 1                       0                 1  \n",
       "Aanmodderfakker          0                       0                 1  \n",
       "\n",
       "[5 rows x 942 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load stacking files\n",
    "metadata_feature_test = pd.read_csv(r'out/meta_test.csv', index_col = 0, header = 0)\n",
    "\n",
    "textual_feature_test = pd.read_csv(r'out/text_yhat_test.csv', index_col = 10, header = 0)\n",
    "textual_feature_test.index.names = ['movie']\n",
    "textual_feature_test = textual_test.drop('goodforairplanes', axis='columns')\n",
    "\n",
    "visual_feature_test = pd.read_csv(r'out/visual_predictions_labels_test.csv', index_col = 0, header = 0)\n",
    "\n",
    "audio_feature_test = pd.read_csv(r'out/audio_yhat_test.csv', index_col = 10, header = 0)\n",
    "audio_feature_test.index.names = ['movie']\n",
    "\n",
    "# merge dataframes\n",
    "#dfs = [metadata_test, metadata_feature_test, textual_test, textual_feature_test, visual_feature_test, \n",
    "#       audio_test, audio_feature_test]\n",
    "dfs = [metadata_test, metadata_feature_test, visual_feature_test]\n",
    "features_test = reduce(lambda left, right: pd.merge(left, right, on = 'movie'), dfs)\n",
    "\n",
    "# rearrange columns\n",
    "features_test = features_test[[c for c in features_test if c not in ['goodforairplanes']] + ['goodforairplanes']]\n",
    "features_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Labe-Feature Stacking we can use the function `label_stacking` with our new train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label-Feature Stacking on the Train Set with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lilli\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\lilli\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\lilli\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\lilli\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\lilli\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\lilli\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\lilli\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\lilli\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\lilli\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\lilli\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Precision': 0.5802380952380952, 'Recall': 0.79, 'F1': 0.6647435897435896}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "label_feature_stacking_train = label_stacking(features_train)\n",
    "label_feature_stacking_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the Results to the Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_cv = {\"Precision\": 0.94, \"Recall\": 0.57, \"F1\": 0.71}\n",
    "label_stacking_cv = {\"Precision\": 0.72, \"Recall\": 0.86, \"F1\": 0.78}\n",
    "label_attribute_stacking_cv = {\"Precision\": 0.71, \"Recall\": 0.79, \"F1\": 0.75}\n",
    "voting_test = {\"Precision\": 0.62, \"Recall\": 0.80, \"F1\": 0.70}\n",
    "label_stacking_test = {\"Precision\": 0.62, \"Recall\": 0.90, \"F1\": 0.73}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAJORITY VOTING CV\n",
      "Paper:  {'Precision': 0.94, 'Recall': 0.57, 'F1': 0.71}\n",
      "Group15:  {'Precision': 0.5882352941176471, 'Recall': 0.8163265306122449, 'F1': 0.6837606837606838}\n",
      "---------------------------------------------------------------------------------------------------\n",
      "LABEL STACKING CV\n",
      "Paper:  {'Precision': 0.72, 'Recall': 0.86, 'F1': 0.78}\n",
      "Group15:  {'Precision': 0.6422619047619047, 'Recall': 0.67, 'F1': 0.638028638028638}\n",
      "---------------------------------------------------------------------------------------------------\n",
      "LABEL ATTRIBUTE STACKING CV\n",
      "Paper:  {'Precision': 0.71, 'Recall': 0.79, 'F1': 0.75}\n",
      "Group15:  {'Precision': 0.5802380952380952, 'Recall': 0.79, 'F1': 0.6647435897435896}\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MAJORITY VOTING TEST\n",
      "Paper:  {'Precision': 0.62, 'Recall': 0.8, 'F1': 0.7}\n",
      "Group15:  {'Precision': 0.580952380952381, 'Recall': 0.7176470588235294, 'F1': 0.6421052631578948}\n",
      "---------------------------------------------------------------------------------------------------\n",
      "LABEL STACKING TEST\n",
      "Paper:  {'Precision': 0.62, 'Recall': 0.9, 'F1': 0.73}\n",
      "Group15:  {'Precision': 0.5344827586206896, 'Recall': 0.36470588235294116, 'F1': 0.4335664335664336}\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"MAJORITY VOTING CV\")\n",
    "print(\"Paper: \", voting_cv)\n",
    "print(\"Group15: \", majority_scores_train)\n",
    "print(\"---------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"LABEL STACKING CV\")\n",
    "print(\"Paper: \", label_stacking_cv)\n",
    "print(\"Group15: \", label_stacking_scores_train)\n",
    "print(\"---------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"LABEL ATTRIBUTE STACKING CV\")\n",
    "print(\"Paper: \", label_attribute_stacking_cv)\n",
    "print(\"Group15: \", label_feature_stacking_train)\n",
    "print(\"---------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"MAJORITY VOTING TEST\")\n",
    "print(\"Paper: \", voting_test)\n",
    "print(\"Group15: \", majority_scores_test)\n",
    "print(\"---------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"LABEL STACKING TEST\")\n",
    "print(\"Paper: \", label_stacking_test)\n",
    "print(\"Group15: \", label_stacking_scores_test)\n",
    "print(\"---------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
